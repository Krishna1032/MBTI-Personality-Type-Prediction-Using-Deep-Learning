{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f598aa67-9143-47a3-94fb-29ecf513c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cc5f9b-5742-429e-9937-345cdd6c489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./mbti_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c34974-98a1-46e4-b658-337dc4fd9e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1727c24c-b01d-42f5-9608-e7c3b5d007af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_row(row):\n",
    "    type = row.iloc[0]\n",
    "    \n",
    "    if type[0] == 'I': I = 1\n",
    "    elif type[0] == 'E': I =  0\n",
    "    else: print('I-E value not found')\n",
    "\n",
    "    if type[1] == 'N': N = 1\n",
    "    elif type[1] == 'S': N =  0\n",
    "    else: print('N-S value not found')\n",
    "\n",
    "    if type[2] == 'T': T = 1\n",
    "    elif type[2] == 'F': T =  0\n",
    "    else: print('T-F value not found')\n",
    "\n",
    "    if type[3] == 'J': J = 1\n",
    "    elif type[3] == 'P': J =  0\n",
    "    else: print('J-P value not found')\n",
    "\n",
    "    return pd.Series({\"I/E\" : I, \"N/S\": N, \"T/F\": T, \"J/P\": J})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df04ab94-15af-49f9-8ea1-a16f1f2fb2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  I/E  N/S  T/F  J/P\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...    1    1    0    1\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...    0    1    1    0\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...    1    1    1    0\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...    1    1    1    1\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...    0    1    1    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.join(data.apply(lambda row: take_row(row), axis = 1))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09ad8cf-a9b1-4781-875a-766b988e3dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T/F\n",
       "0    4694\n",
       "1    3981\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"I/E\"].value_counts()\n",
    "data[\"N/S\"].value_counts()\n",
    "data[\"T/F\"].value_counts()\n",
    "# data[\"J/P\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1afe44-dea9-477d-8711-24aeb5e7d530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x1691e7890>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"N/S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23e65a1-a28a-4445-b208-5935639790d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "unique_type_list = ['INFJ', 'ENTP', 'INTP', 'INTJ', 'ENTJ', 'ENFJ', 'INFP', 'ENFP',\n",
    "       'ISFP', 'ISTP', 'ISFJ', 'ISTJ', 'ESTP', 'ESFP', 'ESTJ', 'ESFJ']\n",
    "\n",
    "def preprocessing(post):\n",
    "    text = post\n",
    "\n",
    "    # remove the pipe character |\n",
    "    text = text.replace(\"|\",\"\")\n",
    "\n",
    "    # remove the links\n",
    "    text = re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"\", text)\n",
    "\n",
    "    # remove all the punctuations and keep the words\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text).lower()\n",
    "\n",
    "    # remove the unwanted spaces > 1\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    # tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # remove the stopwords, mbit mentions, and lammetization\n",
    "    temp = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    text = \" \".join([word for word in temp if word not in [x.lower() for x in unique_type_list]])\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b747caa-a611-4566-a7db-259e915421bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"processed_text\"] = data[\"posts\"].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7422e378-77f0-42c0-a035-273d8dd94439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>moment sportscenter top ten play prankswhat li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>finding lack post alarming sex boring position...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts  I/E  N/S  T/F  \\\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...    1    1    0   \n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...    0    1    1   \n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...    1    1    1   \n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...    1    1    1   \n",
       "4  ENTJ  'You're fired.|||That's another silly misconce...    0    1    1   \n",
       "\n",
       "   J/P                                     processed_text  \n",
       "0    1  moment sportscenter top ten play prankswhat li...  \n",
       "1    0  finding lack post alarming sex boring position...  \n",
       "2    0  good one course say know blessing curse absolu...  \n",
       "3    1  dear enjoyed conversation day esoteric gabbing...  \n",
       "4    1  fired another silly misconception approaching ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c72e56a3-6db3-40cf-a9d7-9a51fb29de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"type\",\"posts\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a06da96e-2d35-4a07-8acf-f899b478fef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>moment sportscenter top ten play prankswhat li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>finding lack post alarming sex boring position...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good one course say know blessing curse absolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dear enjoyed conversation day esoteric gabbing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>fired another silly misconception approaching ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I/E  N/S  T/F  J/P                                     processed_text\n",
       "0    1    1    0    1  moment sportscenter top ten play prankswhat li...\n",
       "1    0    1    1    0  finding lack post alarming sex boring position...\n",
       "2    1    1    1    0  good one course say know blessing curse absolu...\n",
       "3    1    1    1    1  dear enjoyed conversation day esoteric gabbing...\n",
       "4    0    1    1    1  fired another silly misconception approaching ..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c323985d-869c-40bf-b27d-e87ef6ad489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"processed_mbti.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01c599a3-66e9-41f8-8652-5044c25de604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    moment sportscenter top ten play prankswhat li...\n",
      "1    finding lack post alarming sex boring position...\n",
      "2    good one course say know blessing curse absolu...\n",
      "3    dear enjoyed conversation day esoteric gabbing...\n",
      "4    fired another silly misconception approaching ...\n",
      "Name: processed_text, dtype: object\n",
      "0\n",
      "processed_text\n",
      "<class 'str'>    8675\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.processed_text.head())\n",
    "print(data.processed_text.isna().sum())  # Count of NaN values\n",
    "print(data.processed_text.apply(type).value_counts())  # Types present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28c8fed9-490f-405b-9d90-ec4df4d1f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text = data.processed_text.astype(\"string\")\n",
    "labels = data[[\"I/E\", \"N/S\", \"T/F\", \"J/P\"]]\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_train = train_test_split(text, labels, random_state = 42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "342e8e89-9f44-4f9a-8a79-7ecd8a73570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "embedding_dim = 128\n",
    "max_tokens = 10_000\n",
    "\n",
    "vectorizer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens = 10_000,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = 250\n",
    ")\n",
    "\n",
    "vectorizer.adapt(data.processed_text)\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=(1,), dtype=\"string\", name='input_text')\n",
    "\n",
    "# Vectorizer layer\n",
    "x = vectorizer(input_layer)\n",
    "\n",
    "# Shared layers\n",
    "x = Embedding(input_dim = max_tokens, output_dim = embedding_dim)(x)\n",
    "x = Bidirectional(LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0.2))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(20, activation=\"relu\", kernel_initializer='he_normal')(x)\n",
    "\n",
    "# Separate outputs\n",
    "output_IE = Dense(1, activation='sigmoid', name='IE_output')(x)\n",
    "output_NS = Dense(1, activation='sigmoid', name='NS_output')(x)\n",
    "output_TF = Dense(1, activation='sigmoid', name='TF_output')(x)\n",
    "output_JP = Dense(1, activation='sigmoid', name='JP_output')(x)\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=[output_IE, output_NS, output_TF, output_JP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcf9596e-7d5b-4957-9a3b-f52856ac75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics={'IE_output': 'accuracy',\n",
    "             'NS_output': 'accuracy',\n",
    "             'TF_output': 'accuracy',\n",
    "             'JP_output': 'accuracy'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86237154-707a-4839-bb5e-824660a70588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 573ms/step - IE_output_accuracy: 0.7511 - IE_output_loss: 0.5705 - JP_output_accuracy: 0.6032 - JP_output_loss: 0.6786 - NS_output_accuracy: 0.8483 - NS_output_loss: 0.4483 - TF_output_accuracy: 0.5190 - TF_output_loss: 0.7021 - loss: 2.3995 - val_IE_output_accuracy: 0.7615 - val_IE_output_loss: 0.5491 - val_JP_output_accuracy: 0.5864 - val_JP_output_loss: 0.6791 - val_NS_output_accuracy: 0.8556 - val_NS_output_loss: 0.4155 - val_TF_output_accuracy: 0.5378 - val_TF_output_loss: 0.6921 - val_loss: 2.3353\n",
      "Epoch 2/20\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 592ms/step - IE_output_accuracy: 0.7693 - IE_output_loss: 0.5352 - JP_output_accuracy: 0.5998 - JP_output_loss: 0.6743 - NS_output_accuracy: 0.8654 - NS_output_loss: 0.3731 - TF_output_accuracy: 0.5750 - TF_output_loss: 0.6737 - loss: 2.2563 - val_IE_output_accuracy: 0.7615 - val_IE_output_loss: 0.5496 - val_JP_output_accuracy: 0.5864 - val_JP_output_loss: 0.6822 - val_NS_output_accuracy: 0.8562 - val_NS_output_loss: 0.4265 - val_TF_output_accuracy: 0.5999 - val_TF_output_loss: 0.6690 - val_loss: 2.3266\n",
      "Epoch 3/20\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 626ms/step - IE_output_accuracy: 0.7655 - IE_output_loss: 0.5084 - JP_output_accuracy: 0.6104 - JP_output_loss: 0.6597 - NS_output_accuracy: 0.8700 - NS_output_loss: 0.3093 - TF_output_accuracy: 0.7785 - TF_output_loss: 0.4894 - loss: 1.9668 - val_IE_output_accuracy: 0.7603 - val_IE_output_loss: 0.5565 - val_JP_output_accuracy: 0.5630 - val_JP_output_loss: 0.6831 - val_NS_output_accuracy: 0.8482 - val_NS_output_loss: 0.4771 - val_TF_output_accuracy: 0.5986 - val_TF_output_loss: 0.7305 - val_loss: 2.4464\n",
      "Epoch 4/20\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 642ms/step - IE_output_accuracy: 0.7715 - IE_output_loss: 0.4637 - JP_output_accuracy: 0.6988 - JP_output_loss: 0.5968 - NS_output_accuracy: 0.9114 - NS_output_loss: 0.2076 - TF_output_accuracy: 0.8990 - TF_output_loss: 0.2762 - loss: 1.5444 - val_IE_output_accuracy: 0.7449 - val_IE_output_loss: 0.5813 - val_JP_output_accuracy: 0.5501 - val_JP_output_loss: 0.7113 - val_NS_output_accuracy: 0.8267 - val_NS_output_loss: 0.5249 - val_TF_output_accuracy: 0.6294 - val_TF_output_loss: 0.8978 - val_loss: 2.7146\n",
      "Epoch 5/20\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 650ms/step - IE_output_accuracy: 0.8179 - IE_output_loss: 0.3947 - JP_output_accuracy: 0.7832 - JP_output_loss: 0.4818 - NS_output_accuracy: 0.9532 - NS_output_loss: 0.1408 - TF_output_accuracy: 0.9464 - TF_output_loss: 0.1611 - loss: 1.1784 - val_IE_output_accuracy: 0.7253 - val_IE_output_loss: 0.6192 - val_JP_output_accuracy: 0.5581 - val_JP_output_loss: 0.7881 - val_NS_output_accuracy: 0.8119 - val_NS_output_loss: 0.5947 - val_TF_output_accuracy: 0.6011 - val_TF_output_loss: 1.1203 - val_loss: 3.1219\n",
      "Epoch 6/20\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 653ms/step - IE_output_accuracy: 0.8796 - IE_output_loss: 0.2893 - JP_output_accuracy: 0.8356 - JP_output_loss: 0.3835 - NS_output_accuracy: 0.9628 - NS_output_loss: 0.1131 - TF_output_accuracy: 0.9676 - TF_output_loss: 0.1046 - loss: 0.8905 - val_IE_output_accuracy: 0.6829 - val_IE_output_loss: 0.7911 - val_JP_output_accuracy: 0.5501 - val_JP_output_loss: 0.9995 - val_NS_output_accuracy: 0.8254 - val_NS_output_loss: 0.7472 - val_TF_output_accuracy: 0.5937 - val_TF_output_loss: 1.3378 - val_loss: 3.8757\n",
      "Epoch 7/20\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 729ms/step - IE_output_accuracy: 0.9239 - IE_output_loss: 0.1901 - JP_output_accuracy: 0.8922 - JP_output_loss: 0.2683 - NS_output_accuracy: 0.9665 - NS_output_loss: 0.0931 - TF_output_accuracy: 0.9770 - TF_output_loss: 0.0771 - loss: 0.6286 - val_IE_output_accuracy: 0.6816 - val_IE_output_loss: 0.9145 - val_JP_output_accuracy: 0.5532 - val_JP_output_loss: 1.1517 - val_NS_output_accuracy: 0.8058 - val_NS_output_loss: 0.7690 - val_TF_output_accuracy: 0.5882 - val_TF_output_loss: 1.6509 - val_loss: 4.4890\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Training labels for multiple outputs\n",
    "train_labels = {'IE_output': y_train.iloc[:, 0],\n",
    "                'NS_output': y_train.iloc[:, 1],\n",
    "                'TF_output': y_train.iloc[:, 2],\n",
    "                'JP_output': y_train.iloc[:, 3]}\n",
    "\n",
    "val_labels = {'IE_output': y_val.iloc[:, 0],\n",
    "               'NS_output': y_val.iloc[:, 1],\n",
    "               'TF_output': y_val.iloc[:, 2],\n",
    "               'JP_output': y_val.iloc[:, 3]}\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, train_labels,\n",
    "    validation_data=(X_val, val_labels),\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b825bd7-b98a-4f96-90c7-853893b84c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
